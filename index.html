<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.5.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/yelp.ico?v=0.5.0" />






<meta name="description" content="Final Project Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Yelp Review Mining">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Yelp Review Mining">
<meta property="og:description" content="Final Project Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yelp Review Mining">
<meta name="twitter:description" content="Final Project Blog">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> Yelp Review Mining </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Yelp Review Mining</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/05/13/final-report/" itemprop="url">
                  Final Report
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-05-13T00:00:00-04:00" content="2016-05-13">
              2016-05-13
            </time>
          </span>

          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The fast-growing population of consumers and the increasing amount of yelp users has led to a massive amount of customer reviews that are too numerous for a user or a restaurant owner to read themselves. Our project is creating a system to automatically extract and summarize the reviews into 4 categories: Food, Service, Price and Other, and present the users’ attitude towards each category. With the help of our system, besides one restaurant’s overall performance, users could gain a better knowledge of the restaurant’s performance in each category without reading thousands of tedious reviews exhaustively.</p>
<p>Our project can be divided into two parts: Sentence Labeling and Sentiment Analysis. For each sentence in a review, we categorize it into one of four pre-defined categories using our sentence labeling model built on top of a popular topic modeling algorithm called Latent Dirichlet Allocation. For each categorized sentence, we do sentiment analysis and generate a rating for it. Finally, we combine all the sentence ratings in the same categories to generate an average rating for every category.</p>
<h1 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h1><p>Our data is obtained from the <a href="https://www.yelp.com/dataset_challenge" target="_blank" rel="external">Yelp Challenge</a>. The whole dataset is composed of 5 different datasets corresponding to Business, Review, User, Check-in and Tip. In our project, we mainly focus on the Review dataset which contains 2,225,213 user reviews. We also used Business dataset to select only restaurant reviews.</p>
<h1 id="Hypothesis-Assumption"><a href="#Hypothesis-Assumption" class="headerlink" title="Hypothesis/Assumption"></a>Hypothesis/Assumption</h1><p>We first assume that sentence labeling and sentiment analysis are two independent tasks that we can do them separately. It is reasonable as the attitude behind a word will be similar in different topic contents. Based on this, while doing sentiment analysis, we further assume that the review star is a summary of the overall attitude of the review text so that for two reviews sharing the same star score, they should have the same level of positive/negative feeling regardless the users and the restaurants. It may not be completely true as some consumers tend to give higher scores while others don’t. But based on the huge review dataset we have, the consumer bias can be even out and will not affect our result.</p>
<h1 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h1><img src="/images/workflow1.png" title="Main Workflow">
<h2 id="Sentence-Labeling"><a href="#Sentence-Labeling" class="headerlink" title="Sentence Labeling"></a>Sentence Labeling</h2><p>To improve accuracy and performance, we first run a simple test of existence of keywords to the sentence we are categorizing. For example, if a sentence includes the word “price”, we can confidently classify it to Price category without further analyzing.</p>
<img src="/images/workflow2.png" title="LDA Workflow">
<p>For the remaining sentences, we use Latent Dirichlet Allocation(LDA) to discover hidden unlabeled topics. Latent Dirichlet Allocation (LDA) is a generative statistical model which is widely used for discovering underlying topics from text documents. In LDA, each document may be viewed as a mixture of K topics. And each topic is collection of words with Dirichlet distribution. After many experiments, we decided to use a LDA model with 20 topics. For each vectorized sentence, the LDA model will output a list of pairs <code>(i, p)</code>, where <code>i</code> is a topic id, and <code>p</code> is the probability of the sentence belonging to topic <code>i</code>.</p>
<p>Using the keywords in the topics generated by our LDA model, we then manually classify each topic into one or more of the following four groups: “Food”, “Price”, “Service”, “Other”. In specific, we examine all of the topics by plotting out their detailed information using <a href="https://github.com/bmabey/pyLDAvis" target="_blank" rel="external">pyLDAvis</a>, a python library for interactive topic model visualization. And we assign weights of each topic in these four groups. For example, after observing the most frequent words in the topic 1 shown in the visualization below, we might assign:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weights[<span class="number">1</span>] = [<span class="number">0.05</span>, <span class="number">0.8</span>, <span class="number">0.05</span>, <span class="number">0.1</span>]  <span class="comment"># Food, Service, Price, Other</span></span><br></pre></td></tr></table></figure>
<img src="/images/ldavis.png" title="LDA model visualization screenshot">
<p>In the end, we take the dot product of probabilities returned by LDA and weights to generate a list of 4 category scores, and predict the sentence to be in the category that has the max category score.</p>
<h2 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a>Sentiment Analysis</h2><p>Our initial approach for sentiment analysis is using keywords (most frequent non-stop words) sentiment score to predict review star. We go through all 1-star reviews and 5-star reviews and get words that occurs the most frequently in these reviews. We then delete the duplicates which occurs frequently both in the negative reviews and positive reviews. The words remained from the negative keywords and the positive keywords. Then, for each view, the training feature vector is generated based on the occurrence of the words that we obtained above, the training label is the star corresponding to the review. We use Naive Bayes, SVM and Logistic Regression to fit the training data and do the 5-fold cross validation to get the best model. When calculating accuracy, as we need to take the fact that different people have different rating standards into consideration, if the predicted star is in +1/-1 range of the actual star, we treat it as a true predict. In the end, we generate the sentiment score of those keywords based on the best model.</p>
<p>In our second approach for sentiment analysis we focus on sentences rather than reviews. We split 100,000 1-star and 5-star reviews into sentences and then labeled them as negative and positive respectively. Instead of using bag of words model, we used Word2Vec model to better capture the word context and reduce memory usage. After vectorizing our data this way, we used a Artificial Neural Networks to do the classification. Our sentiment analysis model will classify a sentence to be negative or positive with a probability.</p>
<p>For each categorized sentence, we combine its sentiment score and the score for the entire review provided by the reviewer to generate a scaled score for the sentence.</p>
<h2 id="Combining-Results"><a href="#Combining-Results" class="headerlink" title="Combining Results"></a>Combining Results</h2><p>In the end, every sentence in every review will have both a category label and sentiment score. We sum up the sentence scores under each category to generate the average scores of Food, Service and Price for a restaurant.</p>
<h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p>Our first approach for sentiment analysis performs the best with Naive Bayes model with accuracy around 90% on test dataset (with +/- 1 star tolerate). Take into account that our base line of prediction accuracy is around 50%, the first approach does a great job of predicting the star for a review and also support our assumption that the star of people’s review is mainly based on the sentiment of the words in the review.</p>
<p>However, the first approach does not perform so great when we want to use the model to predict the score of each sentence obtained from LDA algorithm. The accuracy goes down sharply because the information contained in a single sentence is much less than in a whole review and the keywords we analysis may not show up in the sentence.</p>
<p>Our second approach for sentiment analysis does a better job for analyzing single sentence with the accuracy around 78%.</p>
<p>For the Sentence Labeling, we are not able to come up with an efficient way to evaluate our model. We did perform manual test for about 100 sentences and got the accuracy of 80%. One thing we noticed during testing is that our model has higher accuracy when predicting a sentence to be Food and Price comparing to Service and Other.</p>
<img src="/images/demo.png" title="Screenshot of final result demo">
<h1 id="Proposal-Goals"><a href="#Proposal-Goals" class="headerlink" title="Proposal Goals"></a>Proposal Goals</h1><p>According to our proposal, we have accomplished the 100% goal of our project.</p>
<p>We have successfully extract import words in reviews and assign them proper sentiment scores. The sentiment scores can be proved to be meaningful and reasonable according to our 90% accuracy(+1/-1 tolerance and baseline 50%) in test data.</p>
<p>We successfully categorize the reviews into Food, Price, and Service and Other using our LDA model. And we further improve the accuracy of the sentence labeling part by filtering sentences with certain keywords and classifying them into their corresponding groups before applying the LDA model.</p>
<h1 id="Further-Discussion"><a href="#Further-Discussion" class="headerlink" title="Further Discussion"></a>Further Discussion</h1><p>The following are some thoughts to better improve our project.</p>
<p>We fail to predict the exact score with high accuracy (without the +/- tolerance, we have 55% accuracy with 20% base line accuracy). Maybe we can take into account the user bias (the average score the user gives to all the reviews) as well to improve the accuracy.</p>
<p>If we can analysis word phrase, such as “not good”, “don’t like”, it can increase the sentiment analysis accuracy</p>
<p>We use <a href="https://radimrehurek.com/gensim/" target="_blank" rel="external">gensim</a> package for the LDA topic modeling, which does not support using seed words for initialization. Our current method of improving accuracy of the sentence labeling part is to filter and classify sentences with certain key words into their corresponding groups before using the LDA model to predict the categories. One possible improvement is to use a modified LDA model that allows initialization with seed words.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://www.yelp.com/html/pdf/YelpDatasetChallengeWinner_ImprovingRestaurants.pdf" target="_blank" rel="external">“Improving Restaurants by Extracting Subtopics from Yelp Reviews.”</a> James Huang, Stephanie Rogers, Eunkwang Joo. University of California, Berkeley. <a href="https://www.conftool.com/iConference2014/index.php?page=browseSessions&amp;form_session=108" target="_blank" rel="external">Presented at iConference 2014 Berlin</a></li>
<li><a href="https://www.yelp.com/html/pdf/YelpDatasetChallengeWinner_HiddenFactors.pdf" target="_blank" rel="external">“Hidden Factors and Hidden Topics: Understanding Rating Dimensions with Review Text.”</a> Julian McAuley, Jure Leskovec. Stanford University.<br>Published in <a href="http://dl.acm.org/citation.cfm?id=2507163" target="_blank" rel="external">ACM RecSys ‘13 Proceedings</a></li>
<li><a href="https://districtdatalabs.silvrback.com/modern-methods-for-sentiment-analysis" target="_blank" rel="external">Modern Methods for Sentiment Analysis, Michael Czerny</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/05/03/post3/" itemprop="url">
                  Blog Post 3
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-05-03T00:00:00-04:00" content="2016-05-03">
              2016-05-03
            </time>
          </span>

          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>In this week, we continued our exploration on topic modeling technique and finalized our implementation plan.</p>
<h1 id="Adjusting-LDA"><a href="#Adjusting-LDA" class="headerlink" title="Adjusting LDA"></a>Adjusting LDA</h1><p>First of all, we have run LDA on the entire dataset and got a reasonable topic modeling model. As mentioned in the last post, we also wanted to integrate user rating into the traditional LDA algorithm.</p>
<img src="/images/lda_all.png" title="LDA result on entire dataset">
<p>Our first attempt was to run LDA on both 1 star and 5 star reviews and then generate two LDA models. I hoped that these LDA models can give vastly different result depending on the sentiment of a given review. However, the two models turned out to be quite similar and are not effective for giving sentiment score.</p>
<img src="/images/lda_five.png" title="LDA result on 5 star reviews">
<p>Our second attempt is to add top positive and negative words from our sentiment analysis result into the dictionary for generating LDA model. These additional words did appear in some of the topics and we could get topics like “good food” or “bad service”. However, the majority of generated topics are still neutral and sometimes we got both positive and negative words in the same topic. Overall, adding words with high sentiment value is not impactful enough to express user sentiment through LDA model.</p>
<img src="/images/lda_negative.png" title="LDA result with negative words">
<p>After these experiments, we have realized that doing sentiment analysis using LDA is not very effective without modifying the algorithm. Instead of going into the trouble of modifying and re-implementing the entire LDA algorithm, we decided to simply have a separate sentiment analysis pass after doing topic modeling with LDA.</p>
<h1 id="Final-Workflow"><a href="#Final-Workflow" class="headerlink" title="Final Workflow"></a>Final Workflow</h1><p>First, we train our LDA model with the yelp dataset. Using the keywords in the topics generated by our LDA model, we then manually classify each topic into one or more of the following groups: “food”, “value”,  “service”, “environment”.</p>
<img src="/images/example_1.png" title="Classified LDA result">
<p>Next, we want to collect the reviews that corresponds to each of these four groups. Since we can also obtain the latent topics for a document along with their probabilities, we choose to split the reviews into sentences, and predict the topics for each sentence. For example:</p>
<img src="/images/example_2.png" title="Prediction of review segments">
<img src="/images/highlights.png" title="Sentences highlighted by category">
<p>One crude approach is to associate every sentence to a topic that has the largest weight. As we can see from the above example, this method works pretty well for sentences which are related to “food” and “service” aspects.</p>
<p>In the end, we will combine this with the results from our sentiment analysis to get the sentiment for each group.</p>
<h1 id="Alternative-Topic-Modeling-Method"><a href="#Alternative-Topic-Modeling-Method" class="headerlink" title="Alternative Topic Modeling Method"></a>Alternative Topic Modeling Method</h1><p>One important characteristic we found in our LDA result is that comparing to Food, the number of important vocabularies belong to other three categories is much smaller. We can actually effectively categorize review segments only based on the existence of keywords we hand picked from the LDA results. For example, all the review sentences including the word “waiter” will be classified into Service category.</p>
<p>This naive approach does have some limitations like not being able to classify a sentence into multiple categories or allow different categories to share keywords. However, it is in some places more flexible than LDA, since we can actively and manually target our categories. For example, it can distinguish Environment and Service more accurately than LDA. We are still figuring out how to integrate this approach into our project, but it certainly provides a good reference point for our topic modeling.</p>
<h1 id="Next"><a href="#Next" class="headerlink" title="Next"></a>Next</h1><p>Now we have got all the pieces we need and we will put them together in the last few days.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/26/post2/" itemprop="url">
                  Blog Post 2
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-04-26T00:00:00-04:00" content="2016-04-26">
              2016-04-26
            </time>
          </span>

          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>In this week, we’ve conducted basic sentiment analysis and a topic modeling to the review texts.</p>
<h1 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a>Sentiment Analysis</h1><p>As one of the goals of our project is to provide special words related to reviews on Yelp along with their sentiments to Yelp Company in order to help yelp better understand their reviews, this week, the first thing we mainly focused on is that we ran machine learning on the reviews and related starts in order to get the sentiment for each of the words. The initial step do this is to count what words occurs the most in all the reviews we have. Then, we got a list of word occurrence times for each positive reviews and negative reviews. As some of the words will appear in both positive and negative reviews, we deleted them. After that, the length of both positive and negative lists are around 160 (all words occurrences times is bigger than 5000). These are words that we want to assign sentiments and give to yelp. However, as we manually went over these lists, some words seems to mean nothing in the aspect of positive or negative, for example, there are words like potato and boyfriend in the positive word list, there are words like email and face in the negative word list. However, as all word counts are above 5000, these words should really something even though they mean nothing to us in the aspect of positive or negative. Thus, our plan is to do the machine learning twice. One with the word lists we have already, another one with the word list that we manually went over with all “non-sense” words deleted.</p>
<p>When doing the machine learning, we found that not all reviews are in a decent format. Some seems to be in a mess which made it hard for us to extract key words from them. Then, what we did is that 1. lowercase all reviews. 2. replace string punctuation with a space. 3. split them and store. After we have each review elements in a good format, we created a list with both positive words and negative words we have. The next step is that for each review, we will create a new string, if one element of the review is in the positive/negative list, the new string will add this word in the corresponding place, otherwise, the string will add “empty” in the corresponding place. Then, using vectorizer.fit_transfrom, we have get our training features. The training labels of the model is composed of the stars related to each review for 1-5, 5 kinds of labels. For the first step, we use the naive Bayes model to train the model. For now, we think it will be kind of hard to exactly predict the label, we will tolerant predict will +-1 error. Maybe our tolerance condition now is too widely open, we will adjust the method in the next two weeks to get a better result. The following are the results we have now. One is for the whole word list, one is for the revised word list which mentioned above.</p>
<img src="/images/02.ml_result.png" title="Machine Learning Result">
<p>In the next week, the first thing we will do is to adjust our machine learning algorithm to get a better sentiment score. In addition, we also want to fit a least square model to our data, which will also give us a sentiment score for each word. Afterwards, we will decide which result seems to be better and accept it.</p>
<h1 id="Topic-Modeling"><a href="#Topic-Modeling" class="headerlink" title="Topic Modeling"></a>Topic Modeling</h1><p>In terms of topic modeling part of the project, we have done the following:</p>
<ol>
<li>Studied some related algorithms.</li>
<li>Studied related python library.</li>
<li>Tested the algorithm on a subset of our data.</li>
<li>Discussed the potential adjustments to the algorithm for our project.</li>
</ol>
<p>Among the papers which mentioned in the final proposal, we decided to  study and try Latent Dirichlet allocation(LDA) first. We now have a clear theoretical understanding of how LDA functions and its characteristics. In short, LDA is a clustering algorithm to discover latent topics from a training corpus. We intent to use it to generate a bunch topics and then manually classify these topics to give suggestion to restaurants.</p>
<p>We then played around with a popular python package for topic modeling called <a href="https://radimrehurek.com/gensim/" target="_blank" rel="external">gensim</a>. Using this library, we performed a test to see how well LDA works on our dataset.</p>
<p>In the test, we used all the restaurant review texts from Arizona (roughly 5% of our entire dataset) as training set. In these review texts, we only kept the words that are nouns to reduce the noise in the outcome. We generated 20 topics with this test and got the result below. The algorithm worked as expected, some groups have clear topic. However, we found the topics generated are still not useful enough for our purpose. We are most interested in the reviewers’ opinion of the dining experience, but the majority of topics generated are about the dining event itself(breakfast, asian food, etc).</p>
<img src="/images/lda_result.png" title="LDA Test Result">
<p>We have realized that the best place to extract reviewers’ opinion, is their rating. Therefore, we have discussed some of the possibilities to integrate rating into our basic LDA model:</p>
<ol>
<li>Add our sentiment result from machine learning into the LDA training dictionary.</li>
<li>Perform LDA on different rating groups.</li>
<li>Modify LDA algorithm to incorporate rating parameter.</li>
</ol>
<p>We’ll try these methods in the final weeks and hopefully get better result.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/19/post1/" itemprop="url">
                  Blog Post 1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-04-19T00:00:00-04:00" content="2016-04-19">
              2016-04-19
            </time>
          </span>

          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>This week, our group paid more attention to the dataset itself as we want to explore more interesting facts that hide in our dataset. The steps taken this week will help us better understand our dataset.</p>
<h1 id="Location-and-Stars"><a href="#Location-and-Stars" class="headerlink" title="Location and Stars"></a>Location and Stars</h1><p>The first thing we noticed is that in the business json file, we have stars and state field of each business. With these information, we all want to see if the star have some special distribution all over the country. As we are doing the cleaning steps, we found our that yelp dataset do not cover all the states in US. We can only find data regarding to the following states [‘PA’, ‘NC’, ‘SC’, ‘WI’, ‘IL’, ‘AZ’, ‘NV’, ‘NM’, ‘AR’, ‘QC’, ‘ON’, ‘TX’, ‘EDH’, ‘MLN’, ‘ELN’, ‘HAM’, ‘SCB’, ‘FIF’, ‘NTH’, ‘BW’, ‘RP’, ‘CA’, ‘KHL’, ‘MN’, ‘MA’, ‘NW’, ‘OR’, ‘AL’]. However, as these stats do not only gather in a certain place which will have huge probability of causing bias, it is all right. Then, we count the number of business regarding to the states, which gives us the following result, [3754, 6162, 271, 2802, 737, 32614, 21233, 1, 1, 4942, 474, 2, 3206, 147, 12, 1, 3, 5, 1, 1048, 18, 3, 1, 1, 1, 1, 1, 1]. As we all know that small numbers can cause bias, what we did is that we ignored all the states that have business data less than 20. In the meaning time, we also keep track of the sum of stars of these business. Thus, finally, we got three lists.</p>
<ul>
<li>All states, [‘PA’, ‘NC’, ‘SC’, ‘WI’, ‘IL’, ‘AZ’, ‘NV’, ‘QC’, ‘ON’, ‘EDH’, ‘MLN’, ‘BW’]</li>
<li>Number of business within each state, [3754, 6162, 271, 2802, 737, 32614, 21233, 4942, 474, 3206, 147, 1048]</li>
<li>Total stars of business within each state, [13892.5, 22113.5, 967.0, 10254.0, 2617.5, 121008.5, 78200.0, 18335.0, 1698.5, 12210.5, 564.5, 3963.0].</li>
</ul>
<p>The last step is to divide the third list by the second list by index, in this step, we got the average star of business in each state as the following [3.701, 3.589, 3.568, 3.66, 3.552, 3.71, 3.683, 3.71, 3.583, 3.809, 3.84, 3.781].</p>
<p>Take a look at the list of average stars, average star of all states is 3.682. As our data is samples, we need to use the sample formula to calculate the variance which is 0.00924 at last. From these analysis, we can see that the average star do not vary too much, they are all in the interval [3.552, 3.84], the maximum difference is less than 0.3.</p>
<p>Then, with only nums, it not easy for us to get a overall understanding how the average stars vary from state to state according to location. Thus, we make the following visualization to help us. When creating the visualiztion, we find another problem that ‘EDH’, ‘MLN’, ‘BW’, ‘ON’, ‘QC’ do not exist as US states. As a result, these parts of data are ignored. The created visualization is shown in the following graph.</p>
<img src="/images/map.post1.png" title="Average rating in each state">
<p>In the visualization, the darker the color is, the higher the average star is. There are states with high average star on both east and west part, which reveals the data is not too bias to be used as a valid dataset. However, as we found out that there are only 7 valid states with enough data, in the next steps, we may want to use the Yelp Api to get more data about other states.</p>
<h1 id="Check-in-Time-Distribution"><a href="#Check-in-Time-Distribution" class="headerlink" title="Check-in Time Distribution"></a>Check-in Time Distribution</h1><p>When further exploring our dataset, we found that in check-in json file we have check-in info for 24 hours a day in the whole week. Then, we come up with the idea that we can use these data to find the check-in pattern with respect of day in week and different hours within a day. After we clean the data, we get the following 7 lists(day in week), each list contain 24 nums(hours).</p>
<ul>
<li>Sunday = [11672, 6793, 4656, 4659, 6340, 11031, 15479, 23794, 31345, 40109, 49002, 71565, 82624, 66888, 58790, 59172, 67284, 81184, 84958, 71604, 51379, 34099, 20309, 13113]</li>
<li>Monday = [9140, 5352, 3533, 3696, 6419, 11185, 16004, 24685, 31388, 38678, 46984, 69591, 79355, 60188, 53369, 56892, 68874, 85823, 91069, 78152, 55278, 35855, 21177, 13397]</li>
<li>Tuesday = [9266, 5474, 3566, 3744, 6262, 11226, 15705, 24949, 31958, 39805, 47032, 70598, 81182, 62740, 55020, 58579, 69970, 88317, 94968, 82354, 58099, 37617, 18451, 14153]</li>
<li>Wednesday = [10466, 6085, 4208, 3700, 6420, 11089, 16079, 25211, 32443, 40629, 48605, 72010, 83665, 64185, 56654, 60532, 72568, 91697, 99198, 87207, 63637, 43412, 27694, 19062]</li>
<li>Thursday = [13549, 8360, 5493, 4736, 6989, 11703, 17660, 28236, 37778, 47623, 57972, 85624, 101500, 81173, 73052, 77023, 91814, 115822, 130199, 122775, 96646, 72325, 51606, 37224]</li>
<li>Friday = [26648, 17131, 10907, 8376, 7128, 9412, 16475, 30624, 51195, 72734, 93083, 116725, 129476, 124565, 111156, 104013, 103802, 113501, 122653, 115377, 95207, 73408, 53660, 39508]</li>
<li>Saturday = [28314, 17893, 10785, 7958, 6457, 7824, 12423, 23639, 41881, 64080, 85120, 106712, 118690, 111135, 95316, 84946, 81315, 84199, 83877, 71611, 53112, 36528, 23570, 16188]</li>
</ul>
<p>It’s not a good way to find the pattern with only several lists of numbers. Thus, we created two visualizations.</p>
<p>The first visualization is number of check-in with respect of day in a week.</p>
<img src="/images/1.post1.png" title="Check-in count for each day in a week">
<p>From the visualization we can see that people tend to go to restaurant in later part of the week. We can see the peak in Friday, which makes sense to all of us as that’s what we do on Friday. However, what we do not expected at first is the number of check-in on Thursday. It is even bigger than the number in Saturday.</p>
<p>The second visualization is the number of check-in with respect of different hours in a day. In this graph, we expect to have two peaks in about 12:00 am and 6:00 pm as they are typical time of eating. In this visualization, we chose to use line graph to better reveal the change pattern of numbers.</p>
<img src="/images/2.post1.png" title="Check-in count for time in a day">
<p>From the graph we can easily see the two peaks in 12:00-13:00, 18:00-19:00 which also fits our expectation. If we ignore the two peaks for a second, the graph is somewhat like a normal distribution in its two tails, which means most of the check-in happens in the middle part of the day, from 9:00 to 21:00.</p>
<h1 id="Next-Step"><a href="#Next-Step" class="headerlink" title="Next Step"></a>Next Step</h1><p>As we have deeply explored the data, the next thing we want to do is to study the review dataset, and predict the star for reviews and businesses with the text reviews provided using the bag-of-words model and other natural language processing algorithms such as LDA (latent Dirichlet allocation) and Word2Vec.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/03/21/Midterm-Report/" itemprop="url">
                  Midterm Report
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-03-21T08:20:44-04:00" content="2016-03-21">
              2016-03-21
            </time>
          </span>

          

          
            
          

          

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The dataset we are using is from <a href="https://www.yelp.com/dataset_challenge/" target="_blank" rel="external">Yelp Dataset Challenge</a>. There are six subsets in total: business, review, user, check-in, tip and photos.  And all the data are in json format.  We have been using the business, review and user datasets, which contains 77,445 businesses, 2,225,213 reviews and 552,339 user profiles.  More specifically, we use the following data from these three sets:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">'business'</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'business_id'</span>: (encrypted business id),</span><br><span class="line">        <span class="string">'state'</span>: (state),</span><br><span class="line">        <span class="string">'stars'</span>: (star rating, rounded to half-stars),</span><br><span class="line">        <span class="string">'review_count'</span>: (review count)</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="string">'review'</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'user_id'</span>: (encrypted user id),</span><br><span class="line">        <span class="string">'business_id'</span>: (encrypted business id),</span><br><span class="line">        <span class="string">'stars'</span>: (star rating, rounded to half-stars),</span><br><span class="line">        <span class="string">'text'</span>: (review text)</span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    <span class="string">'user'</span>:</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">'user_id'</span>: (encrypted user id),</span><br><span class="line">        <span class="string">'review_count'</span>: (review count),</span><br><span class="line">        <span class="string">'average_stars'</span>: (floating point average, like <span class="number">4.31</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Based on these data, we want to achieve the following two goals:</p>
<ol>
<li><p>Given a user’s review text, predict its star rating automatically. Our idea of approaching this goal is to create a sentiment file specifically for Yelp to predict review stars (1-5)</p>
<p> (a) This sentiment file should perform better at predicting review stars based on the review text comparing to the sentiment file we use during the ml lab.</p>
<p> (b) We may take into account that some users may tend to give overall higher stars. So if have time, we will take into the reviewer’s average stars into account and predict the review stars based on both the text and the user.</p>
</li>
<li><p>Study the different factors that affect the overall ratings of restaurants and create a report for each restaurant, giving them scores on their performance based on the review for each restaurant. The report will look like below:</p>
<p> Business id:<br> Service: Score from 1 to 5<br> Food: Score from 1 to 5<br> Location: Score from 1 to 5<br> Environment: Score from 1 to 5</p>
</li>
</ol>
<p>And the report is aimed to help restaurants to improve their weakness and to help users have a better idea about how the restaurants are.</p>
<h1 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h1><p>A basic study of the business dataset reveals that the reviews we received for businesses on yelp are not evenly distributed among different states in the US.  In fact, our dataset contains most reviews for businesses in Nevada and Arizona.</p>
<img src="/images/map1.png" title="review count for each state">
<p>We also plot the distribution for the stars of businesses and find that most stores have average stars above 3:</p>
<img src="/images/barchart1.png" title="business average rating">
<p>Next, we focus on extracting useful information from the review dataset. It contains mostly 4-star and 5-star reviews.</p>
<img src="/images/barchart2.png" title="rating distribution">
<p>We look at all the 5-star (most positive) reviews as well as all the 1-star (most negative) review. We want to check the hypothesis below:<br>Positive words (words which should assign higher sentiment value) will appear in the 5-star reviews very often while not in the 1-star reviews. =&gt; Words appears very frequently in the 5-star reviews but rarely shows up from the 1-star reviews are the positive words.</p>
<ol>
<li><p>Negative words (words which should assign lower sentiment value) will appear in the 1-star reviews very often while not in the 5-star reviews. =&gt; Words appears very frequently in the 1-star reviews but rarely shows up from the 5-star reviews are the negative words.</p>
</li>
<li><p>Below are two word clouds, which show the most positive words as well the most negative words we find from the review based on our hypothesis. The bigger the word is, the more frequently it shows up in 5-star/1-star reviews. The rank of the word will show up if you place your mouse on the word.</p>
</li>
</ol>
<p><div id="wc1"></div></p>
<p align="center" style="color:#aaa"><strong>positive word cloud</strong></p>

<p><div id="wc2"></div></p>
<p align="center" style="color:#aaa"><strong>negative word cloud</strong></p>


<p>We perform the following steps to get the cleaned data:</p>
<ol>
<li>Lowercase, delete all the stop words and punctuation and all reviews in other language.</li>
<li>Take all the reviews with scores 5 and 1, find the top 500 words that are most frequently shown in the reviews, named as wordlist1 (top 500 words in 1-star review) and wordlist5 (top 500 words in 5-star review).</li>
<li>Compare the two lists, delete any words that exist in both list.</li>
<li>The words left in the wordlist5 are the positive words and the words left in wordlist1 are the negative words.</li>
</ol>
<p>Based on the two word clouds above, our hypothesis on the positive words are supported: most of the “positive words” we find, especially the top 50 words, have a positive meaning with it, such as “awesome”, “fresh”, “excellent”, “favorite”, happy”, etc. However, our hypothesis of the negative words are not strongly supported: many of the “negative words” we find don’t have any negative meaning behind it.</p>
<p>A natural follow-up is to look at the most-frequent two-word and three-word phrases.</p>
<h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><p>For the machine learning part of our project, this time, we want to find the relationship between the restaurant’s actual star and the [city, state, price range, current_state] set. In order to make our result more reliable, we need to do some operations to the data we have.</p>
<p>First, we noticed that there is an attribute in the dataset called [review_count] and we counted number of all the reviews and average them to get a average review_count in the dataset to be 31.6. Then, what we do is to ingore all the data with a review_count less than the average number we just get. We took this step as small review_count will definitely cause a big bias on the rating as well as the star of the restaurant. Then, regarding to a restaurant, price_range is also extremely important. However, not all data in our dataset have a price_range attribute. Thus, what we mainly do is to just pick the data with the price_range tag to do the learning. In addition, the current status of the restaurant will also affect the star of the restaurant badly in common sense. In all, with all the parameters above plus [city, state] pair. We generated our training features.</p>
<p>Next, we need to move to the training label part. For training labels, we count the average star of all restaurants that have above average reviews and price range tag, again, in order to avoid bias of the data. Then, we give label 1 to stars more or equal to average star and 0 to stars less than averae star. In this way, we obtained all training labels and we start doing machine learining.</p>
<p>We used nb, log, svm models to model the data and did the 10-folder cross validation. The result turned out to be in the interval of [0.55, 0.60] and when print 10 most and 10 least informative features, the results all turned out to be city name.</p>
<img src="/images/ml_result.png" title="machine learning result">
<p>Analysis: If our accuracy of the 10-folder is high and the most/least informative features are all cities, we can conclude that the city where the restaurant locationed in really matters. However, in our case, the accuray is not high, thus, we cannot draw the conclusion that the city matters. On the other side, our accuracy is not always oscillation below and above 0.5, which means the feature set can actually give us some clue about the star of the restaurant. This is awesome as we can further explore the dataset to obtain a better result. Maybe we can combaine this machine learning method with other methods later to realize our final goal.</p>
<p>Conclusion: As for this machine learning method, we cannot rely on [city, state, price_range, current_state] to predict the star of the restaurant very correctly.</p>
<p><a href="https://www.dropbox.com/s/lc6e57ulzlukjox/midml.zip?dl=0" target="_blank" rel="external">Download code for machine learning</a></p>
<h1 id="Further-Discussion"><a href="#Further-Discussion" class="headerlink" title="Further Discussion"></a>Further Discussion</h1><p>There are two main difficulties we are facing with this project:</p>
<ol>
<li><p>The review set alone amounts to around 2GB of data. It takes a long time to do machine learning and test our hypothesis each time.</p>
</li>
<li><p>There are lots of feature generation methods as well as machine learning models. So far we have used word frequency counting, and experimented with the three classifiers from the machine learning lab: naive Bayes, logistic regression and support vector machine. But we are still trying to gain a deeper insight of the review data, and working on to combine it with the business and user data set.</p>
</li>
</ol>
<p>To solve these problems, we are hoping to learn more about MapReduce and AWS from the next lab, which will help us build a more effective way to process the data. We have also conducted preliminary literature search, and are planning to study latent factor recommender system.  If we have more time we will also read the paper Hidden factors and hidden topics: understanding rating dimensions with review text by J. McAuley and J. Leskovec, and try to apply the method in the paper to improve our model.</p>
<p>Overall, after our initial exploration of the data, we believe this is a deep dataset and contains lots of interesting hidden information. And we think we are on track with the project.</p>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script> <!-- JQUERY -->
<script src="http://d3js.org/d3.v3.min.js"></script>

<script>
// Word cloud layout by Jason Davies, http://www.jasondavies.com/word-cloud/
// Algorithm due to Jonathan Feinberg, http://static.mrfeinberg.com/bv_ch03.pdf
(function() {

if (typeof define === "function" && define.amd) define(["d3"], cloud);
else cloud(this.d3);

function cloud(d3) {
  d3.layout.cloud = function cloud() {
    var size = [256, 256],
        text = cloudText,
        font = cloudFont,
        fontSize = cloudFontSize,
        fontStyle = cloudFontNormal,
        fontWeight = cloudFontNormal,
        rotate = cloudRotate,
        padding = cloudPadding,
        spiral = archimedeanSpiral,
        words = [],
        timeInterval = Infinity,
        event = d3.dispatch("word", "end"),
        timer = null,
        random = Math.random,
        cloud = {};

    cloud.start = function() {
      var board = zeroArray((size[0] >> 5) * size[1]),
          bounds = null,
          n = words.length,
          i = -1,
          tags = [],
          data = words.map(function(d, i) {
            d.text = text.call(this, d, i);
            d.font = font.call(this, d, i);
            d.style = fontStyle.call(this, d, i);
            d.weight = fontWeight.call(this, d, i);
            d.rotate = rotate.call(this, d, i);
            d.size = ~~fontSize.call(this, d, i);
            d.padding = padding.call(this, d, i);
            return d;
          }).sort(function(a, b) { return b.size - a.size; });

      if (timer) clearInterval(timer);
      timer = setInterval(step, 0);
      step();

      return cloud;

      function step() {
        var start = Date.now();
        while (Date.now() - start < timeInterval && ++i < n && timer) {
          var d = data[i];
          d.x = (size[0] * (random() + .5)) >> 1;
          d.y = (size[1] * (random() + .5)) >> 1;
          cloudSprite(d, data, i);
          if (d.hasText && place(board, d, bounds)) {
            tags.push(d);
            event.word(d);
            if (bounds) cloudBounds(bounds, d);
            else bounds = [{x: d.x + d.x0, y: d.y + d.y0}, {x: d.x + d.x1, y: d.y + d.y1}];
            // Temporary hack
            d.x -= size[0] >> 1;
            d.y -= size[1] >> 1;
          }
        }
        if (i >= n) {
          cloud.stop();
          event.end(tags, bounds);
        }
      }
    }

    cloud.stop = function() {
      if (timer) {
        clearInterval(timer);
        timer = null;
      }
      return cloud;
    };

    function place(board, tag, bounds) {
      var perimeter = [{x: 0, y: 0}, {x: size[0], y: size[1]}],
          startX = tag.x,
          startY = tag.y,
          maxDelta = Math.sqrt(size[0] * size[0] + size[1] * size[1]),
          s = spiral(size),
          dt = random() < .5 ? 1 : -1,
          t = -dt,
          dxdy,
          dx,
          dy;

      while (dxdy = s(t += dt)) {
        dx = ~~dxdy[0];
        dy = ~~dxdy[1];

        if (Math.min(dx, dy) > maxDelta) break;

        tag.x = startX + dx;
        tag.y = startY + dy;

        if (tag.x + tag.x0 < 0 || tag.y + tag.y0 < 0 ||
            tag.x + tag.x1 > size[0] || tag.y + tag.y1 > size[1]) continue;
        // TODO only check for collisions within current bounds.
        if (!bounds || !cloudCollide(tag, board, size[0])) {
          if (!bounds || collideRects(tag, bounds)) {
            var sprite = tag.sprite,
                w = tag.width >> 5,
                sw = size[0] >> 5,
                lx = tag.x - (w << 4),
                sx = lx & 0x7f,
                msx = 32 - sx,
                h = tag.y1 - tag.y0,
                x = (tag.y + tag.y0) * sw + (lx >> 5),
                last;
            for (var j = 0; j < h; j++) {
              last = 0;
              for (var i = 0; i <= w; i++) {
                board[x + i] |= (last << msx) | (i < w ? (last = sprite[j * w + i]) >>> sx : 0);
              }
              x += sw;
            }
            delete tag.sprite;
            return true;
          }
        }
      }
      return false;
    }

    cloud.timeInterval = function(_) {
      return arguments.length ? (timeInterval = _ == null ? Infinity : _, cloud) : timeInterval;
    };

    cloud.words = function(_) {
      return arguments.length ? (words = _, cloud) : words;
    };

    cloud.size = function(_) {
      return arguments.length ? (size = [+_[0], +_[1]], cloud) : size;
    };

    cloud.font = function(_) {
      return arguments.length ? (font = d3.functor(_), cloud) : font;
    };

    cloud.fontStyle = function(_) {
      return arguments.length ? (fontStyle = d3.functor(_), cloud) : fontStyle;
    };

    cloud.fontWeight = function(_) {
      return arguments.length ? (fontWeight = d3.functor(_), cloud) : fontWeight;
    };

    cloud.rotate = function(_) {
      return arguments.length ? (rotate = d3.functor(_), cloud) : rotate;
    };

    cloud.text = function(_) {
      return arguments.length ? (text = d3.functor(_), cloud) : text;
    };

    cloud.spiral = function(_) {
      return arguments.length ? (spiral = spirals[_] || _, cloud) : spiral;
    };

    cloud.fontSize = function(_) {
      return arguments.length ? (fontSize = d3.functor(_), cloud) : fontSize;
    };

    cloud.padding = function(_) {
      return arguments.length ? (padding = d3.functor(_), cloud) : padding;
    };

    cloud.random = function(_) {
      return arguments.length ? (random = _, cloud) : random;
    };

    return d3.rebind(cloud, event, "on");
  };

  function cloudText(d) {
    return d.text;
  }

  function cloudFont() {
    return "serif";
  }

  function cloudFontNormal() {
    return "normal";
  }

  function cloudFontSize(d) {
    return Math.sqrt(d.value);
  }

  function cloudRotate() {
    return (~~(Math.random() * 6) - 3) * 30;
  }

  function cloudPadding() {
    return 1;
  }

  // Fetches a monochrome sprite bitmap for the specified text.
  // Load in batches for speed.
  function cloudSprite(d, data, di) {
    if (d.sprite) return;
    c.clearRect(0, 0, (cw << 5) / ratio, ch / ratio);
    var x = 0,
        y = 0,
        maxh = 0,
        n = data.length;
    --di;
    while (++di < n) {
      d = data[di];
      c.save();
      c.font = d.style + " " + d.weight + " " + ~~((d.size + 1) / ratio) + "px " + d.font;
      var w = c.measureText(d.text + "m").width * ratio,
          h = d.size << 1;
      if (d.rotate) {
        var sr = Math.sin(d.rotate * cloudRadians),
            cr = Math.cos(d.rotate * cloudRadians),
            wcr = w * cr,
            wsr = w * sr,
            hcr = h * cr,
            hsr = h * sr;
        w = (Math.max(Math.abs(wcr + hsr), Math.abs(wcr - hsr)) + 0x1f) >> 5 << 5;
        h = ~~Math.max(Math.abs(wsr + hcr), Math.abs(wsr - hcr));
      } else {
        w = (w + 0x1f) >> 5 << 5;
      }
      if (h > maxh) maxh = h;
      if (x + w >= (cw << 5)) {
        x = 0;
        y += maxh;
        maxh = 0;
      }
      if (y + h >= ch) break;
      c.translate((x + (w >> 1)) / ratio, (y + (h >> 1)) / ratio);
      if (d.rotate) c.rotate(d.rotate * cloudRadians);
      c.fillText(d.text, 0, 0);
      if (d.padding) c.lineWidth = 2 * d.padding, c.strokeText(d.text, 0, 0);
      c.restore();
      d.width = w;
      d.height = h;
      d.xoff = x;
      d.yoff = y;
      d.x1 = w >> 1;
      d.y1 = h >> 1;
      d.x0 = -d.x1;
      d.y0 = -d.y1;
      d.hasText = true;
      x += w;
    }
    var pixels = c.getImageData(0, 0, (cw << 5) / ratio, ch / ratio).data,
        sprite = [];
    while (--di >= 0) {
      d = data[di];
      if (!d.hasText) continue;
      var w = d.width,
          w32 = w >> 5,
          h = d.y1 - d.y0;
      // Zero the buffer
      for (var i = 0; i < h * w32; i++) sprite[i] = 0;
      x = d.xoff;
      if (x == null) return;
      y = d.yoff;
      var seen = 0,
          seenRow = -1;
      for (var j = 0; j < h; j++) {
        for (var i = 0; i < w; i++) {
          var k = w32 * j + (i >> 5),
              m = pixels[((y + j) * (cw << 5) + (x + i)) << 2] ? 1 << (31 - (i % 32)) : 0;
          sprite[k] |= m;
          seen |= m;
        }
        if (seen) seenRow = j;
        else {
          d.y0++;
          h--;
          j--;
          y++;
        }
      }
      d.y1 = d.y0 + seenRow;
      d.sprite = sprite.slice(0, (d.y1 - d.y0) * w32);
    }
  }

  // Use mask-based collision detection.
  function cloudCollide(tag, board, sw) {
    sw >>= 5;
    var sprite = tag.sprite,
        w = tag.width >> 5,
        lx = tag.x - (w << 4),
        sx = lx & 0x7f,
        msx = 32 - sx,
        h = tag.y1 - tag.y0,
        x = (tag.y + tag.y0) * sw + (lx >> 5),
        last;
    for (var j = 0; j < h; j++) {
      last = 0;
      for (var i = 0; i <= w; i++) {
        if (((last << msx) | (i < w ? (last = sprite[j * w + i]) >>> sx : 0))
            & board[x + i]) return true;
      }
      x += sw;
    }
    return false;
  }

  function cloudBounds(bounds, d) {
    var b0 = bounds[0],
        b1 = bounds[1];
    if (d.x + d.x0 < b0.x) b0.x = d.x + d.x0;
    if (d.y + d.y0 < b0.y) b0.y = d.y + d.y0;
    if (d.x + d.x1 > b1.x) b1.x = d.x + d.x1;
    if (d.y + d.y1 > b1.y) b1.y = d.y + d.y1;
  }

  function collideRects(a, b) {
    return a.x + a.x1 > b[0].x && a.x + a.x0 < b[1].x && a.y + a.y1 > b[0].y && a.y + a.y0 < b[1].y;
  }

  function archimedeanSpiral(size) {
    var e = size[0] / size[1];
    return function(t) {
      return [e * (t *= .1) * Math.cos(t), t * Math.sin(t)];
    };
  }

  function rectangularSpiral(size) {
    var dy = 4,
        dx = dy * size[0] / size[1],
        x = 0,
        y = 0;
    return function(t) {
      var sign = t < 0 ? -1 : 1;
      // See triangular numbers: T_n = n * (n + 1) / 2.
      switch ((Math.sqrt(1 + 4 * sign * t) - sign) & 3) {
        case 0:  x += dx; break;
        case 1:  y += dy; break;
        case 2:  x -= dx; break;
        default: y -= dy; break;
      }
      return [x, y];
    };
  }

  // TODO reuse arrays?
  function zeroArray(n) {
    var a = [],
        i = -1;
    while (++i < n) a[i] = 0;
    return a;
  }

  var cloudRadians = Math.PI / 180,
      cw = 1 << 11 >> 5,
      ch = 1 << 11,
      canvas,
      ratio = 1;

  if (typeof document !== "undefined") {
    canvas = document.createElement("canvas");
    canvas.width = 1;
    canvas.height = 1;
    ratio = Math.sqrt(canvas.getContext("2d").getImageData(0, 0, 1, 1).data.length >> 2);
    canvas.width = (cw << 5) / ratio;
    canvas.height = ch / ratio;
  } else {
    // Attempt to use node-canvas.
    canvas = new Canvas(cw << 5, ch);
  }

  var c = canvas.getContext("2d"),
      spirals = {
        archimedean: archimedeanSpiral,
        rectangular: rectangularSpiral
      };
  c.fillStyle = c.strokeStyle = "red";
  c.textAlign = "center";
}

})();
</script>

<script src="/javascript/wc.js"></script>

          
        
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/logo.png"
               alt="CS1951a" />
          <p class="site-author-name" itemprop="name">CS1951a</p>
          <p class="site-description motion-element" itemprop="description">Final Project Blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">5</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        <div class="links-of-blogroll motion-element">
          
            <div class="links-of-blogroll-title">Group Members</div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.pusheen.com/" target="_blank">Chang Liu [cl137]</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.pusheen.com/" target="_blank">Hanwen Ren [hren]</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.pusheen.com/" target="_blank">Zheng Shi [zs9]</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.pusheen.com/" target="_blank">Ziyuan Chen [zchen24]</a>
                </li>
              
            </ul>
          
        </div>

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CS1951a</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  


  




<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>

  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=0.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=0.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=0.5.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=0.5.0"></script>



  



  



  
  
  

  


</body>
</html>
